import csv
import json
import os
from multiprocessing import Pool

import click

# https://github.com/aneesha/RAKE
from rake_nltk import Rake
# modified from: https://github.com/davidadamojr/TextRank
from ranked_textrank import extract_key_phrases
# https://github.com/titipata/keyphrase_extraction (renamed locally for lack of confusion)
from keyphrase_extraction_tfidf import keyphrase_extraction_tfidf

N_KEYWORDS = 20

def get_rake_keywords(cluster_info):
    """Get keywords using RAKE algorithm.

    Args:
        cluster_info: single dict of cluster information, with keys name and text
    Returns: list of strings, keywords
    """
    rake = Rake()
    rake.extract_keywords_from_text(cluster_info['text'])
    return [cluster_info['name'], rake.get_ranked_phrases()[:N_KEYWORDS]]


def get_textrank_keywords(cluster_info):
    """Get keywords using Textrank algorithm.

    Args:
        cluster_info: single dict of cluster information, with keys name and text
    Returns: list of strings, keywords
    """
    return [cluster_info['name'], list(extract_key_phrases(cluster_info['text']))[:N_KEYWORDS]]


def get_tfidf_keywords(cluster_infos):
    """Get keywords using tfidf scores.

    Args:
        cluster_infos: list of dicts of cluster information, with keys name and text
    Returns: list lists of strings, keywords for each text
    """
    texts = [cluster_info['text'] for cluster_info in cluster_infos]
    return [[cluster_info['name'], keywords] for cluster_info, keywords
            in zip(cluster_infos, list(keyphrase_extraction_tfidf(texts, num_key=N_KEYWORDS)))]


def iter_cluster_info(input_dir):
    """Iterate cluster information.

    Args:
        input_dir: string, directory containing files generated by cluster.py, where
            each file contains all the text docs for each cluster.
    Yields: dicts, with cluster info, with name and text keys
    """
    for filename in os.listdir(input_dir):
        with open(os.path.join(input_dir, filename), 'rt', encoding='utf-8') as f:
            texts = []
            for line in f:
                texts.append(json.loads(line)['text'])
        yield {'name': filename, 'text': '\n'.join(texts)}


@click.command()
@click.option('--input_dir', '-i', help='Input directory, of cluster files generated by cluster.py')
@click.option('--output_filename', '-o', help='File path for csv output file')
@click.option('--num_procs', '-p', default=4, help='Number of wprker processes for computation')
@click.option('--keyword_fn_name', '-k', default='textrank', help='"textrank", "tfidf", or "rake" -- '
                                                                  'keyword algorithm to use')
def main(input_dir, output_filename, num_procs, keyword_fn_name):
    p = Pool(num_procs)
    if keyword_fn_name == 'tfidf':
        keyword_data = get_tfidf_keywords([cluster_info for cluster_info in iter_cluster_info(input_dir)])
    else:
        keyword_fn = get_rake_keywords if keyword_fn_name == 'rake' else get_textrank_keywords
        keyword_data = p.map(keyword_fn, iter_cluster_info(input_dir))
    with open(output_filename, 'wt', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(['cluster_id', 'keywords'])
        for row in keyword_data:
            writer.writerow(row)


if __name__ == '__main__':
    main()
